{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2eec76",
   "metadata": {},
   "source": [
    "#Basis of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a8a08",
   "metadata": {},
   "source": [
    "1. represent categorical festures by numeric vectors.\n",
    "\n",
    "Type      index     one-hot encoding\n",
    "\n",
    "Apple      1        [1,0,0,....]\n",
    "Banana     2        [0,1,0.....]\n",
    "Pear       3        [0,0,1,....]\n",
    "\n",
    "count from \"1\": Reserve \"0\" (whose one-hot encode is[0,0....,0] for unknown or missing features.\n",
    "\n",
    "dimension of vector-space: the number of different features.\n",
    "\n",
    "Why one-hot vector? apple + Banana = 3 meaningless\n",
    "\n",
    "[1,0,0,....] + [0,1,0.....] = [1,1,0,....] meaning apple and pear occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4508a14",
   "metadata": {},
   "source": [
    "2. Processing Text Data\n",
    "\n",
    "\n",
    "step1: Tokenization(Text to words)\n",
    "\n",
    "Text = \"... to be or not...\"\n",
    "\n",
    "WordsList = [..., to, be, ir, not,...]\n",
    "\n",
    "tips:\n",
    "1. remove infrequent words,stop words,e.g, \"the\",\"a\",\"of\",etc.\n",
    "2. Typo correction (\"goood\" to \"good\")\n",
    "3. Uppercase to lowercase\n",
    "\n",
    "step2: Count Word Frequncecies(Hashmap)\n",
    "\n",
    "sort the frequency list in the descedning order.\n",
    "\n",
    "Replace \"frequency\" by \"index\"(starting from 1.)\n",
    "\n",
    "step3: One-Hot Encoding\n",
    "\n",
    "one-hot vector' dimension = vocabulary\n",
    "\n",
    "-if a word (e.g.typo) cannot be found in the dictionary, then simply ignore it, or encode it as 0.\n",
    "\n",
    "step4:Align Sequences(docuements have different number of words)\n",
    "\n",
    "problem: the training samples are not aligned(they have different lengths, w elements)\n",
    "solution: longer than w: cut off the text to keep w words, e.g. w= 7. \n",
    "          shoter than w: add zeros to keep w words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf4d54",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "texts[i] = \"the cat sat on the mat\"\n",
    "\n",
    "1. tokenization\n",
    "\n",
    "token_index = [\"the\", \"cat\", \"sat\", \"on\", \"mat\"]\n",
    "\n",
    "2. build dictionary\n",
    "\n",
    "token_index = {\"the\":1, \"cat\":2, \"sat\":3, \"on\":4, \"mat\":5}\n",
    "print(token_index)\n",
    "\n",
    "3. encoding index\n",
    "sequences[i] = [1,2,3,4,1,5]\n",
    "\n",
    "4. one-hot encoding\n",
    "e1 = [1,0,0....]\n",
    "e2 = [0,1,0....]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5489f28",
   "metadata": {},
   "source": [
    "word embedding:\n",
    "\n",
    "map the one-hot vectors to low-dimensional vectors by transformation(a parameter matrix which can be learned\n",
    "from training data.)\n",
    "\n",
    "e.g. Xi(d*1) = P(d*v) * ei(v*1)\n",
    "\n",
    "d(rows):assigned by youself (cross-validation)\n",
    "v(columns):the number of dimensions = vocabulary \n",
    "P:parameter matrix\n",
    "ei: the one-hot vector of the i-th word in dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f79da",
   "metadata": {},
   "source": [
    "Vocabulary: the number of unique words in the dictionary\n",
    "\n",
    "\n",
    "Why removing infrequent words?\n",
    "\n",
    "Infrequent words are usually meaningless,e.g.,\n",
    " 1. Name entities,e.g., \"Kathy\"\n",
    " 2. Typos,e.g., \"prinse\" wrong spelling \"prince\"\n",
    " \n",
    "Bigger vocabulary = higher-dim one-hot vectors.\n",
    " 1. slower computation\n",
    " 2. more parameters in word-embedding layer.\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
